"""
SearchAgent V3 - —Å–∫—Ä–µ–π–ø–∏—Ç –∫–∞—Ç–∞–ª–æ–≥–∏ Telegram –∫–∞–Ω–∞–ª–æ–≤ –Ω–∞–ø—Ä—è–º—É—é

–ò—Å—Ç–æ—á–Ω–∏–∫–∏:
- tlgrm.ru - –∫—Ä—É–ø–Ω—ã–π —Ä—É—Å—Å–∫–∏–π –∫–∞—Ç–∞–ª–æ–≥
- tgstat.ru - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–∞–Ω–∞–ª–æ–≤
- –î—Ä—É–≥–∏–µ –∫–∞—Ç–∞–ª–æ–≥–∏

–õ–æ–≥–∏–∫–∞:
1. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç URL –¥–ª—è —Å–∫—Ä–µ–π–ø–∏–Ω–≥–∞ (–≥–æ—Ä–æ–¥, –∫–∞—Ç–µ–≥–æ—Ä–∏—è)
2. –°–∫—Ä–µ–π–ø–∏—Ç –∫–∞—Ç–∞–ª–æ–≥–∏
3. –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞–Ω–∞–ª—ã
4. LLM —Ä–∞–Ω–∂–∏—Ä—É–µ—Ç
"""

import re
import logging
import asyncio
from typing import Dict, Any, List
from openai import OpenAI
from config import settings
import httpx
from bs4 import BeautifulSoup
from urllib.parse import urljoin, quote

logger = logging.getLogger(__name__)


class SearchAgentV3:
    """
    –ê–≥–µ–Ω—Ç –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ –∫–∞—Ç–∞–ª–æ–≥–∏ Telegram –∫–∞–Ω–∞–ª–æ–≤
    """
    
    def __init__(self):
        # Using DeepSeek API (OpenAI-compatible)
        self.client = OpenAI(
            api_key=settings.deepseek_api_key,
            base_url="https://api.deepseek.com"
        )
        self.model = "deepseek-chat"
        
        # HTTP –∫–ª–∏–µ–Ω—Ç
        self.http_client = httpx.AsyncClient(
            timeout=15.0,
            follow_redirects=True,
            headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                "Accept-Language": "ru-RU,ru;q=0.9,en;q=0.8",
            }
        )
        
        # –ú–∞–ø–ø–∏–Ω–≥ –≥–æ—Ä–æ–¥–æ–≤ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –¥–ª—è URL
        self.city_mapping = {
            "–ú–æ—Å–∫–≤–∞": "moscow",
            "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥": "saint-petersburg",
            "–ö–∞–∑–∞–Ω—å": "kazan",
            "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥": "ekaterinburg",
            "–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥": "nizhny-novgorod",
            "–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫": "novosibirsk",
            "–°–∞–º–∞—Ä–∞": "samara",
            "–û–º—Å–∫": "omsk",
            "–ö—Ä–∞—Å–Ω–æ—è—Ä—Å–∫": "krasnoyarsk",
            "–í–æ—Ä–æ–Ω–µ–∂": "voronezh",
            "–ü–µ—Ä–º—å": "perm",
            "–í–æ–ª–≥–æ–≥—Ä–∞–¥": "volgograd",
            "–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä": "krasnodar",
            "–°–∞—Ä–∞—Ç–æ–≤": "saratov",
            "–¢—é–º–µ–Ω—å": "tyumen",
            "–¢–æ–ª—å—è—Ç—Ç–∏": "tolyatti",
            "–ò–∂–µ–≤—Å–∫": "izhevsk",
            "–ë–∞—Ä–Ω–∞—É–ª": "barnaul",
            "–£–ª—å—è–Ω–æ–≤—Å–∫": "ulyanovsk",
            "–ò—Ä–∫—É—Ç—Å–∫": "irkutsk",
            "–•–∞–±–∞—Ä–æ–≤—Å–∫": "khabarovsk",
            "–Ø—Ä–æ—Å–ª–∞–≤–ª—å": "yaroslavl",
            "–í–ª–∞–¥–∏–≤–æ—Å—Ç–æ–∫": "vladivostok",
            "–ú–∞—Ö–∞—á–∫–∞–ª–∞": "makhachkala",
            "–¢–æ–º—Å–∫": "tomsk",
            "–û—Ä–µ–Ω–±—É—Ä–≥": "orenburg",
            "–ö–µ–º–µ—Ä–æ–≤–æ": "kemerovo",
            "–ù–æ–≤–æ–∫—É–∑–Ω–µ—Ü–∫": "novokuznetsk",
            "–†—è–∑–∞–Ω—å": "ryazan",
            "–ê—Å—Ç—Ä–∞—Ö–∞–Ω—å": "astrakhan",
            "–ù–∞–±–µ—Ä–µ–∂–Ω—ã–µ –ß–µ–ª–Ω—ã": "naberezhnye-chelny",
            "–ü–µ–Ω–∑–∞": "penza",
            "–õ–∏–ø–µ—Ü–∫": "lipetsk",
            "–ö–∏—Ä–æ–≤": "kirov",
            "–ß–µ–±–æ–∫—Å–∞—Ä—ã": "cheboksary",
            "–¢–≤–µ—Ä—å": "tver",
            "–ö–∞–ª–∏–Ω–∏–Ω–≥—Ä–∞–¥": "kaliningrad",
            "–ë—Ä—è–Ω—Å–∫": "bryansk",
            "–ò–≤–∞–Ω–æ–≤–æ": "ivanovo",
            "–ú–∞–≥–Ω–∏—Ç–æ–≥–æ—Ä—Å–∫": "magnitogorsk",
            "–ö—É—Ä—Å–∫": "kursk",
            "–°–æ—á–∏": "sochi",
            "–°—Ç–∞–≤—Ä–æ–ø–æ–ª—å": "stavropol",
            "–£–ª–∞–Ω-–£–¥—ç": "ulan-ude",
            "–¢—É–ª–∞": "tula",
            "–í–æ–ª–æ–≥–¥–∞": "vologda"
        }
        
        # –ß–µ—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫
        self.blacklisted_usernames = {
            'gmail', 'mail', 'yandex', 'yahoo', 'outlook', 'hotmail', 'icloud',
            'instagram', 'facebook', 'twitter', 'tiktok', 'youtube', 'linkedin',
            'magenta', 'telekom', 'katyperry', 'justinbieber'
        }
    
    async def find_relevant_chats(
        self,
        persona: Dict[str, Any],
        limit: int = 20
    ) -> List[Dict[str, Any]]:
        """
        –ò—â–µ—Ç Telegram-—á–∞—Ç—ã —á–µ—Ä–µ–∑ –∫–∞—Ç–∞–ª–æ–≥–∏
        
        Args:
            persona: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–µ—Ä—Å–æ–Ω—ã
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —á–∞—Ç–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        logger.info(f"üîç Searching Telegram chats for: {persona.get('generated_name')}")
        
        city = persona.get('city', '–ú–æ—Å–∫–≤–∞')
        interests = persona.get('interests', [])
        
        logger.info(f"City: {city}, Interests: {interests[:3]}")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º URLs –¥–ª—è —Å–∫—Ä–µ–π–ø–∏–Ω–≥–∞
        urls_to_scrape = self._generate_catalog_urls(city, interests)
        logger.info(f"Generated {len(urls_to_scrape)} catalog URLs to scrape")
        
        # –°–∫—Ä–µ–π–ø–∏–º –∫–∞—Ç–∞–ª–æ–≥–∏
        all_channels = await self._scrape_catalogs(urls_to_scrape)
        logger.info(f"Found {len(all_channels)} UNIQUE channels")
        
        if not all_channels:
            logger.warning("No channels found via catalogs!")
            return []
        
        # LLM —Ä–∞–Ω–∂–∏—Ä—É–µ—Ç –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        ranked_chats = await self._rank_chats_with_llm(persona, list(all_channels.values()))
        
        return ranked_chats[:limit]
    
    def _generate_catalog_urls(self, city: str, interests: List[str]) -> List[Dict[str, Any]]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç URLs –∫–∞—Ç–∞–ª–æ–≥–æ–≤ –¥–ª—è —Å–∫—Ä–µ–π–ø–∏–Ω–≥–∞"""
        
        urls = []
        
        # 1. TLGRM.RU - –ø–æ–∏—Å–∫ –ø–æ –≥–æ—Ä–æ–¥—É
        city_en = self.city_mapping.get(city, city.lower())
        
        urls.append({
            'url': f"https://tlgrm.ru/channels?search={quote(city)}",
            'source': 'tlgrm.ru',
            'type': 'city_search',
            'city': city
        })
        
        # 2. –ü–æ–∏—Å–∫ –ø–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º
        for interest in interests[:3]:
            urls.append({
                'url': f"https://tlgrm.ru/channels?search={quote(interest)}",
                'source': 'tlgrm.ru',
                'type': 'interest_search',
                'interest': interest
            })
        
        # 3. TGSTAT.RU - –∫–∞—Ç–∞–ª–æ–≥
        urls.append({
            'url': f"https://tgstat.ru/search?q={quote(city)}",
            'source': 'tgstat.ru',
            'type': 'city_search',
            'city': city
        })
        
        return urls
    
    async def _scrape_catalogs(self, urls: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
        """–°–∫—Ä–µ–π–ø–∏—Ç –∫–∞—Ç–∞–ª–æ–≥–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ"""
        
        logger.info(f"üåê Scraping {len(urls)} catalog pages...")
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Å–∫—Ä–µ–π–ø–∏–Ω–≥
        tasks = [self._scrape_catalog_page(url_data) for url_data in urls]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã
        all_channels = {}
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"Error scraping {urls[i]['url']}: {result}")
                continue
            
            if result:
                for username, channel_data in result.items():
                    if username not in all_channels:
                        all_channels[username] = channel_data
        
        return all_channels
    
    async def _scrape_catalog_page(self, url_data: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
        """–°–∫—Ä–µ–π–ø–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–∞—Ç–∞–ª–æ–≥–∞"""
        
        url = url_data['url']
        source = url_data['source']
        
        logger.info(f"  üìÑ Scraping {source}: {url[:80]}...")
        
        try:
            response = await self.http_client.get(url)
            response.raise_for_status()
            
            html = response.text
            logger.info(f"    ‚úì Loaded {len(html)} chars")
            
            soup = BeautifulSoup(html, 'lxml')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–Ω–∞–ª—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            if source == 'tlgrm.ru':
                channels = self._extract_from_tlgrm(soup, url_data)
            elif source == 'tgstat.ru':
                channels = self._extract_from_tgstat(soup, url_data)
            else:
                channels = {}
            
            logger.info(f"    ‚úì Extracted {len(channels)} channels")
            
            return channels
            
        except Exception as e:
            logger.warning(f"    ‚úó Error: {e}")
            return {}
    
    def _extract_from_tlgrm(self, soup: BeautifulSoup, url_data: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞–Ω–∞–ª—ã —Å tlgrm.ru"""
        
        channels = {}
        
        # –ò—â–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ t.me/
        links = soup.find_all('a', href=re.compile(r't\.me/'))
        
        for link in links:
            href = link.get('href', '')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º username
            match = re.search(r't\.me/([a-zA-Z0-9_]+)', href)
            if not match:
                continue
            
            username = match.group(1)
            
            if not self._is_valid_username(username):
                continue
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞ —Ä—è–¥–æ–º
            title = link.get_text(strip=True) or username
            description = ""
            
            # –ò—â–µ–º parent —ç–ª–µ–º–µ–Ω—Ç —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º
            parent = link.find_parent('div', class_=re.compile(r'channel|item|card'))
            if parent:
                description = parent.get_text(strip=True)[:200]
            
            channels[username] = {
                'username': f"@{username}",
                'title': title[:100],
                'description': description,
                'source_url': url_data['url'],
                'confidence': 'high'
            }
        
        return channels
    
    def _extract_from_tgstat(self, soup: BeautifulSoup, url_data: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞–Ω–∞–ª—ã —Å tgstat.ru"""
        
        channels = {}
        
        # –ò—â–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ t.me/
        links = soup.find_all('a', href=re.compile(r'(t\.me/|tgstat\.ru/channel/)'))
        
        for link in links:
            href = link.get('href', '')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º username
            match = re.search(r'(?:t\.me|tgstat\.ru/channel)/([a-zA-Z0-9_]+)', href)
            if not match:
                continue
            
            username = match.group(1)
            
            if not self._is_valid_username(username):
                continue
            
            title = link.get_text(strip=True) or username
            
            channels[username] = {
                'username': f"@{username}",
                'title': title[:100],
                'description': '',
                'source_url': url_data['url'],
                'confidence': 'high'
            }
        
        return channels
    
    def _is_valid_username(self, username: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å Telegram username"""
        
        username_lower = username.lower()
        
        if username_lower in self.blacklisted_usernames:
            return False
        
        if len(username) < 5 or len(username) > 32:
            return False
        
        if '.' in username or '___' in username:
            return False
        
        if username.endswith('_') or username.startswith('_'):
            return False
        
        if re.search(r'\d{3,}$', username):
            return False
        
        if not username[0].isalpha():
            return False
        
        return True
    
    async def _rank_chats_with_llm(
        self,
        persona: Dict[str, Any],
        channels: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """LLM –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–∞–Ω–∞–ª–æ–≤"""
        
        if not channels:
            return []
        
        channels_for_llm = channels[:30]
        
        channels_list = "\n".join([
            f"{i+1}. {ch['username']} - {ch['title']}"
            for i, ch in enumerate(channels_for_llm)
        ])
        
        prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ Telegram. –û—Ü–µ–Ω–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–∞–Ω–∞–ª–æ–≤/–≥—Ä—É–ø–ø –¥–ª—è —ç—Ç–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:

–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:
- –ì–æ—Ä–æ–¥: {persona.get('city')}
- –ò–Ω—Ç–µ—Ä–µ—Å—ã: {', '.join(persona.get('interests', []))}
- –ü—Ä–æ—Ñ–µ—Å—Å–∏—è: {persona.get('occupation')}
- –í–æ–∑—Ä–∞—Å—Ç: {persona.get('age')}

–ù–∞–π–¥–µ–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã:
{channels_list}

–û—Ü–µ–Ω–∏ –ö–ê–ñ–î–´–ô –∫–∞–Ω–∞–ª –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (0.0-1.0):
- 1.0 = –ò–î–ï–ê–õ–¨–ù–û –ø–æ–¥—Ö–æ–¥–∏—Ç (–≥—Ä—É–ø–ø–∞ –≥–æ—Ä–æ–¥–∞, —Ç–æ—á–Ω–æ–µ –ø–æ–ø–∞–¥–∞–Ω–∏–µ –ø–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º)
- 0.8 = –û—Ç–ª–∏—á–Ω–æ (—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥—Ä—É–ø–ø–∞ –ø–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º)
- 0.5 = –°—Ä–µ–¥–Ω–µ (–º–æ–∂–µ—Ç –±—ã—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ)
- 0.3 = –°–ª–∞–±–æ (–∫–æ—Å–≤–µ–Ω–Ω–∞—è —Å–≤—è–∑—å)
- 0.0 = –ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç

–ü–†–ò–û–†–ò–¢–ï–¢–´:
1. –ì—Ä—É–ø–ø—ã/—á–∞—Ç—ã –ì–û–†–û–î–ê –¥–ª—è –æ–±—â–µ–Ω–∏—è (group/supergroup) - –í–´–°–®–ò–ô –ü–†–ò–û–†–ò–¢–ï–¢!
2. –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≥—Ä—É–ø–ø—ã –ø–æ –ò–ù–¢–ï–†–ï–°–ê–ú –≤ –≥–æ—Ä–æ–¥–µ
3. –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞
4. –û–±—â–∏–µ –∫–∞–Ω–∞–ª—ã –≥–æ—Ä–æ–¥–∞ (–Ω–æ–≤–æ—Å—Ç–∏)

–û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø (group/channel/supergroup) - –≥—Ä—É–ø–ø—ã –ª—É—á—à–µ —á–µ–º –∫–∞–Ω–∞–ª—ã!

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ - JSON –º–∞—Å—Å–∏–≤:
[
  {{
    "username": "@example",
    "relevance_score": 0.9,
    "chat_type": "group",
    "reason": "–ì—Ä—É–ø–ø–∞ –≥–æ—Ä–æ–¥–∞ –¥–ª—è –æ–±—â–µ–Ω–∏—è"
  }},
  ...
]

–¢–û–õ–¨–ö–û JSON!"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                temperature=0.3,
                max_tokens=3000,
                messages=[
                    {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ Telegram. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ JSON."},
                    {"role": "user", "content": prompt}
                ]
            )
            
            response_text = response.choices[0].message.content
            
            # Parse JSON
            if "```json" in response_text:
                json_str = response_text.split("```json")[1].split("```")[0].strip()
            elif "```" in response_text:
                json_str = response_text.split("```")[1].split("```")[0].strip()
            else:
                json_str = response_text.strip()
            
            import json
            rankings = json.loads(json_str)
            
            username_to_channel = {ch['username']: ch for ch in channels_for_llm}
            
            ranked_chats = []
            for rank in rankings:
                username = rank.get('username', '')
                if username in username_to_channel:
                    original = username_to_channel[username]
                    ranked_chats.append({
                        "chat_username": username,
                        "chat_title": original.get('title', ''),
                        "chat_description": original.get('description', ''),
                        "chat_type": rank.get('chat_type', 'unknown'),
                        "member_count": None,
                        "relevance_score": rank.get('relevance_score', 0.5),
                        "relevance_reason": rank.get('reason', '')
                    })
            
            logger.info(f"LLM ranked {len(ranked_chats)} chats")
            
            for i, chat in enumerate(sorted(ranked_chats, key=lambda x: x['relevance_score'], reverse=True)[:5]):
                logger.info(f"  {i+1}. {chat['chat_username']} (score: {chat['relevance_score']:.2f})")
            
            return ranked_chats
            
        except Exception as e:
            logger.error(f"Error ranking chats: {e}")
            return [{
                "chat_username": ch['username'],
                "chat_title": ch.get('title', ''),
                "chat_description": ch.get('description', ''),
                "chat_type": "unknown",
                "member_count": None,
                "relevance_score": 0.5,
                "relevance_reason": "Found via search"
            } for ch in channels_for_llm]
    
    async def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç HTTP –∫–ª–∏–µ–Ω—Ç"""
        await self.http_client.aclose()




